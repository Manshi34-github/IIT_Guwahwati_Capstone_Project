{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f9ca920-8985-4d2e-a5b3-7d4a1c69c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2679e376-9abd-4520-9b1b-6a376f703f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id     author_id  inbound                      created_at  \\\n",
      "0    119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
      "1    119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
      "2    119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
      "3    119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
      "4    119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
      "\n",
      "                                                text response_tweet_id  \\\n",
      "0  @AppleSupport causing the reply to be disregar...            119236   \n",
      "1  @105835 Your business means a lot to us. Pleas...               NaN   \n",
      "2  @76328 I really hope you all change but I'm su...            119238   \n",
      "3  @105836 LiveChat is online at the moment - htt...            119241   \n",
      "4  @VirginTrains see attached error message. I've...            119243   \n",
      "\n",
      "   in_response_to_tweet_id  \n",
      "0                      NaN  \n",
      "1                 119239.0  \n",
      "2                      NaN  \n",
      "3                 119242.0  \n",
      "4                 119240.0  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('twitter_dataset.csv')\n",
    "print(data.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cef10a47-d2ee-4fb8-bcfd-9ce5ecae7da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a24385-fd15-4a01-8b55-7e793f843a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'tweet_id' and 'response_tweet_id' columns are of the same type\n",
    "data['tweet_id'] = data['tweet_id'].astype(str)\n",
    "data['response_tweet_id'] = data['response_tweet_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c4aad87-9b29-4bc7-b8b5-78dcbdac7cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out necessary columns\n",
    "data = data[['tweet_id', 'author_id', 'inbound', 'text', 'response_tweet_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3d38b9d-3769-44f3-837f-5ecfab6133ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for customer queries (inbound=True) and support responses (inbound=False)\n",
    "customer_queries = data[data['inbound'] == True]\n",
    "support_responses = data[data['inbound'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdf55e1c-8a32-4885-b8b6-7c0f61c5121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge customer queries with their corresponding responses\n",
    "merged_data = customer_queries.merge(support_responses, left_on='tweet_id', right_on='response_tweet_id', suffixes=('_query', '_response'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63ee4d65-4abc-4ee7-8f06-30069f9a2032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "merged_data = merged_data[['text_query', 'text_response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df4bf04a-0012-498e-bc7a-22e419ebf8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          text_query  \\\n",
      "0  @VirginTrains see attached error message. I've...   \n",
      "1  @VirginTrains yep, I've tried laptop too sever...   \n",
      "2  @VirginTrains I still haven't heard &amp; the ...   \n",
      "3  @SpotifyCares Thanks! Version 8.4.22.857 armv7...   \n",
      "4  @SpotifyCares No, but I've moved speaker to ab...   \n",
      "\n",
      "                                       text_response  \n",
      "0  @105836 LiveChat is online at the moment - htt...  \n",
      "1  @105836 Have you tried from another device, Mi...  \n",
      "2  @105836 That's what we're here for Miriam ðŸ˜Š  T...  \n",
      "3  @105840 Hi there! What device is this happenin...  \n",
      "4  @105840 Thanks. The distance could possibly af...  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the merged data\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6a15e-f72f-43b4-9fcf-83ad3de7052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Generating Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2692995-f5c4-477c-b133-4062781dbae2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m      3\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-proj-kNkKP6PUdcS6ezBMcjW1T3BlbkFJaasbud6r4mTt8B8fTofO\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"sk-proj-kNkKP6PUdcS6ezBMcjW1T3BlbkFJaasbud6r4mTt8B8fTofO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d51d09c-da9e-403f-96c7-d4aae0c66e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text data\n",
    "def preprocess(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef3f93-db21-4a50-a474-da2ac435d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "merged_data['text_query'] = merged_data['text_query'].apply(preprocess)\n",
    "merged_data['text_response'] = merged_data['text_response'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55e318a2-4cbe-4d80-80ac-587146253581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a response using GPT-3.5\n",
    "def generate_response(query):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=f\"Customer query: {query}\\nSupport response:\",\n",
    "        max_tokens=150,\n",
    "        temperature=0.7,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.5,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2733d561-fd0b-44ae-8f91-af40d19ffabc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sample_query \u001b[38;5;241m=\u001b[39m merged_data\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_query\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_query\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response\u001b[39m(query):\n\u001b[0;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      4\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-003\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m         prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSupport response:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[1;32m      7\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m      8\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m      9\u001b[0m         frequency_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     10\u001b[0m         presence_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'openai' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sample_query = merged_data.iloc[0]['text_query']\n",
    "print(generate_response(sample_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b282b-2e4f-4bdf-aba0-fcb664ade86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask API for Customer Queries\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app=Flask(twitter_customer_dataset)\n",
    "\n",
    "@app.route('/generate-response', methods=['POST'])\n",
    "def generate_response_api():\n",
    "    data = request.json\n",
    "    query = data['query']\n",
    "    response = generate_response(query)\n",
    "    return jsonify({\"response\": response})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc258530-a6ac-438b-852a-4bf17233a55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
